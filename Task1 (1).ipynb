{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***News Topic Classifier Using BERT***"
      ],
      "metadata": {
        "id": "neqNX9nqt0GZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Import Libraries***"
      ],
      "metadata": {
        "id": "peq3UTj9ulLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary Hugging Face and processing libraries\n",
        "!pip install -q transformers[torch] datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "L00ARcWj16dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Gradio\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "cxM-eKWLJNLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXvGkpJ2tifM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "import evaluate\n",
        "\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, pipeline\n",
        "from datasets import load_dataset\n",
        "import gradio as gr\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Check the labels mapping\n",
        "labels = dataset[\"train\"].features[\"label\"].names\n",
        "num_labels = len(labels)\n",
        "print(num_labels)\n",
        "print(f\"Labels: {labels}\")\n"
      ],
      "metadata": {
        "id": "6CFRpm8VuhmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][:5]"
      ],
      "metadata": {
        "id": "ylY_jhFf2pps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Padding and truncation are essential for BERT's 512-token limit\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "# Apply tokenization to the whole dataset\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "8LRsY5In3HLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=num_labels\n",
        ")"
      ],
      "metadata": {
        "id": "QvUpUhltzVT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n"
      ],
      "metadata": {
        "id": "h373Tsg3z-0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-news-classifier\",\n",
        "    eval_strategy=\"epoch\",      # Evaluate at the end of every epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate='2e-5',          # Standard BERT fine-tuning rate\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,          # BERT usually converges in 2-4 epochs\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True,                   # Enable mixed precision for faster training on GPU\n",
        "    report_to=\"none\"             # Prevents logging to external tools like W&B unless set up\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Q5vMM1iC0yH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a classification pipeline\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "# Test headline\n",
        "headline = \"The central bank decided to raise interest rates to combat inflation.\"\n",
        "prediction = classifier(headline)\n",
        "\n",
        "# Map the label ID back to the class name\n",
        "label_idx = int(prediction[0]['label'].split('_')[-1])\n",
        "print(f\"Headline: {headline}\")\n",
        "print(f\"Predicted Category: {labels[label_idx]} (Score: {prediction[0]['score']:.4f})\")\n"
      ],
      "metadata": {
        "id": "O2LA-5uE1of3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get predictions on the test set\n",
        "output = trainer.predict(tokenized_dataset[\"test\"])\n",
        "y_true = output.label_ids\n",
        "y_pred = np.argmax(output.predictions, axis=-1)\n",
        "\n",
        "# 2. Generate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# 3. Plotting using Seaborn\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix: BERT News Topic Classifier')\n",
        "plt.show()\n",
        "\n",
        "# 4. Print detailed classification report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n"
      ],
      "metadata": {
        "id": "TUbG9QnVGPJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save model and tokenizer to your Drive\n",
        "model.save_pretrained(\"/content/drive/MyDrive/bert-news-classifier\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/bert-news-classifier\")"
      ],
      "metadata": {
        "id": "L6EogsLqHjaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define the prediction function\n",
        "def classify_news(text):\n",
        "    # Get predictions from the pipeline\n",
        "    # We set top_k=None to get probabilities for ALL categories\n",
        "    predictions = classifier(text, top_k=None)\n",
        "\n",
        "    # Format the results for Gradio's Label component\n",
        "    # It expects a dictionary: {\"Category Name\": probability_float}\n",
        "    formatted_outputs = {}\n",
        "    for pred in predictions:\n",
        "        label_idx = int(pred['label'].split('_')[-1])\n",
        "        label_name = labels[label_idx]\n",
        "        formatted_outputs[label_name] = float(pred['score'])\n",
        "\n",
        "    return formatted_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "T_iF5xmRIEpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create the Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=classify_news,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Enter a news headline or snippet here...\", label=\"News Text\"),\n",
        "    outputs=gr.Label(num_top_classes=4, label=\"Topic Prediction\"),\n",
        "    title=\"BERT News Topic Classifier\",\n",
        "    description=\"This model uses BERT fine-tuned on the AG News dataset to categorize news into World, Sports, Business, or Sci/Tech.\",\n",
        "    examples=[\n",
        "        [\"The local soccer team won the championship after a dramatic penalty shootout.\"],\n",
        "        [\"Global markets tumbled today as investors reacted to new inflation data.\"],\n",
        "        [\"NASA's latest rover has successfully landed on the Martian surface to look for signs of water.\"],\n",
        "        [\"Diplomats are meeting in Geneva to discuss a new ceasefire agreement.\"]\n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EkJ_RCHBJ06t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Launch the app\n",
        "# share=True creates a public URL you can send to anyone for 72 hours\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NT8jDayNJ2vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip ./bert-news-classifier\n",
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "metadata": {
        "id": "ZeY_qB8CJ7JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Log in (it will provide a link to get your Access Token)\n",
        "# Ensure your token has 'WRITE' permissions\n",
        "notebook_login()\n",
        "\n",
        "# 2. Push the model and tokenizer to the Hub\n",
        "# Replace 'your-username' with your actual Hugging Face username\n",
        "model_name = \"bert-news-classifier-agnews\"\n",
        "model.push_to_hub(model_name)\n",
        "tokenizer.push_to_hub(model_name)"
      ],
      "metadata": {
        "id": "0gcliKGDMshi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EHQCmMlL5Ny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}